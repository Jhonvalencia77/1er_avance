{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad6375bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35377c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos la función\n",
    "def concatenar(start,end,verbose=False):    \n",
    "    #Decimos la ruta de los archivos\n",
    "    #basepath = \"/media/jonathan/JHON/Tesis/DatosTesis/raw_data/%.4d%.2d%.2d_maestra_1_mitma_distrito.csv\"\n",
    "    basepath = \"/media/jonathan/JHON/Tesis/DatosTesis/MatrizDeViajes/Distritos/FicherosDiarios/1erPeriodo/%.4d%.2d%.2d_maestra_1_mitma_distrito.csv\"\n",
    "    #Definimos una lista con las fehas de inicio y final que se analizarán, esta lista se guardará en \"dates\"\n",
    "    dates = pd.date_range(start, end)\n",
    "    \n",
    "    #El simbolo % es el operador de modulo(residuo de un problema de división) \n",
    "    #El simbolo % en cadenas compara si dos textos son iguales y arroja un True or False(Carro=Caro->False)\n",
    "    #Se hace un ciclo for para capturar cada timestamp y luego se pasa cada una de las fechas al basepath\n",
    "    paths = [basepath % (timestamp.year, timestamp.month, timestamp.day) for timestamp in dates]\n",
    "\n",
    "    n = 0\n",
    "    \n",
    "    #Creamos 2 dataframe vacios\n",
    "    timeseries_o = pd.DataFrame({})\n",
    "    timeseries_d = pd.DataFrame({})\n",
    "    \n",
    "    #Hacemos un recorrido por cada uno de los paths (nombre completo del archivo) \n",
    "    for path in paths:\n",
    "        \n",
    "        #Verifica si la variable de función \"verbose esta en True\", Si es asi entonces imprime el porcentaje de archivos concatenados\n",
    "        if verbose: print(path, \"%.2f%%\" % (float(n) * 100 / len(paths)))\n",
    "        \n",
    "        #Leemos cada uno de los archivos csv y lo guardamos en la variable \"data\"\n",
    "        #Le datos a las columnas de fEcha, origen y destino un formato tipo string\n",
    "        \n",
    "        data = pd.read_csv(path, dtype={\"fecha\": str,\n",
    "                                        \"origen\": str,\n",
    "                                        \"destino\": str}, sep='|', usecols=['fecha','origen','viajes','distancia'],index_col=0, parse_dates=True)\n",
    "        \n",
    "        data2 = pd.read_csv(path, dtype={\"fecha\": str,\n",
    "                                        \"origen\": str,\n",
    "                                        \"destino\": str}, sep='|', usecols=['fecha','destino','viajes','distancia'],index_col=0, parse_dates=True)\n",
    "        \n",
    "        timeseries_o = timeseries_o.append(data)\n",
    "        timeseries_d = timeseries_d.append(data2)\n",
    "        print(timeseries_o)\n",
    "        \n",
    "        #Acotamos los datos y solo utlizamos aquellos datos que tienen una distancia mayor a 002-005        \n",
    "        #data = data[data.distancia >= \"010-050\"]\n",
    "        #print(data)\n",
    "        \n",
    "        #data = data[data.distancia >= \"002-005\"]\n",
    "        \n",
    "        #El método pivot_table permite reorganizar en forma de tabla un dataframe,las columnas de esta tabla\n",
    "        #ahora son los distritos de \"origen\", el periodo (hora del dia) ahora es el indice y representa las filas \n",
    "        #de la tabla y los datos que se presentan corresponden al # de viajes en determinada hora del día (00-23) \n",
    "        #dependiendo del distrito de origen.  \n",
    "        #table_o = data.pivot_table(\"viajes\", index=\"periodo\", columns=[\"origen\"], aggfunc=np.sum)        \n",
    "        \n",
    "        '''\n",
    "        table_o = data.pivot_table(data, values='origen','viajes','distancia', columns=['origen','viajes','distancia'], index=\"periodo\")\n",
    "        print(table_o)\n",
    "        \n",
    "        #Cambiamos a tipo flotante los valores de la tabla creada\n",
    "        table_o = table_o.astype(np.float32)\n",
    "        \n",
    "        #Consulta la forma del indice, en este caso el indice es la variable periodo (00-23) tiene que dar 24,\n",
    "        #por las 24 horas del día. \n",
    "        #Se hace para proteger de una excepción si el distrito en cuestion no tiene registros de viajes \n",
    "        \n",
    "        if table_o.index.shape[0] != 24:  \n",
    "            j = 0                           \n",
    "            for i in range(24):\n",
    "                if table_o.index[i] != (i+j):\n",
    "                    print (data.fecha.iloc[0],i+j,\"origen sin registros!\")\n",
    "                    table_o.loc[i+j] = 0\n",
    "                    j += 1\n",
    "                if (i + j) == 23: break\n",
    "            table_o = table_o.sort_index() #sort_index devuelve un nuevo datafRame ordenado por etiqueta si la table es False, de lo contrario actualiza la tabla y retorna un NONE\n",
    "            \n",
    "        #Crea una nueva columa \"ds\" con la fecha, fecha.iloc[0] devuelve \"20200214\"-\"20200215\"... y la hora en formato 24h        \n",
    "        table_o[\"ds\"] = pd.date_range(data.fecha.iloc[0], \"%s 23:00:00\" % (data.fecha.iloc[0]), freq=\"H\")\n",
    "        \n",
    "        #Fija como indice la columna ds\n",
    "        table_o = table_o.set_index(\"ds\")\n",
    "        \n",
    "        #los datos que no tengan registros y aparezcan como NaN el metodo fillna los pondrá en 0\n",
    "        table_o = table_o.fillna(0)\n",
    "        \n",
    "        #Añade los datos de los diferentes archivos a una sola variable llamada timeseries_o\n",
    "        timeseries_o = timeseries_o.append(table_o)\n",
    "        \n",
    "\n",
    "        table_d = data.pivot_table(\"viajes\", \"periodo\", [\"destino\"], aggfunc='sum')\n",
    "        table_d = table_d.astype(np.float32)\n",
    "        if table_d.index.shape[0] != 24:\n",
    "            j = 0\n",
    "            for i in range(24):\n",
    "                if table_d.index[i] != (i + j):\n",
    "                    print(data.fecha.iloc[0], i + j, \"destino sin registros!\")\n",
    "                    table_d.loc[i + j] = 0\n",
    "                    j += 1\n",
    "                if (i + j) == 23: break\n",
    "            table_d = table_d.sort_index()\n",
    "        table_d[\"ds\"] = pd.date_range(data.fecha.iloc[0], \"%s 23:00:00\" % (data.fecha.iloc[0]), freq=\"H\")\n",
    "        table_d = table_d.set_index(\"ds\")\n",
    "        table_d = table_d.fillna(0)\n",
    "        timeseries_d = timeseries_d.append(table_d)\n",
    "\n",
    "        n += 1\n",
    "        \n",
    "        '''\n",
    "        \n",
    "    return timeseries_o, timeseries_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a82ae6d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7146/1256356991.py:37: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  timeseries_o = timeseries_o.append(data)\n",
      "/tmp/ipykernel_7146/1256356991.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  timeseries_d = timeseries_d.append(data2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              origen distancia  viajes\n",
      "fecha                                 \n",
      "2020-02-14  01001_AM   002-005   9.775\n",
      "2020-02-14  01001_AM   005-010   8.754\n",
      "2020-02-14  01001_AM   002-005   8.431\n",
      "2020-02-14  01001_AM   010-050   9.775\n",
      "2020-02-14  01001_AM   002-005   6.007\n",
      "...              ...       ...     ...\n",
      "2020-02-14   5200108  0005-002  62.860\n",
      "2020-02-14   5200108  0005-002  23.569\n",
      "2020-02-14   5200108   002-005  11.225\n",
      "2020-02-14   5200108  0005-002  11.225\n",
      "2020-02-14   5200108   002-005  11.225\n",
      "\n",
      "[7232427 rows x 3 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7146/1256356991.py:37: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  timeseries_o = timeseries_o.append(data)\n",
      "/tmp/ipykernel_7146/1256356991.py:38: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  timeseries_d = timeseries_d.append(data2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              origen distancia  viajes\n",
      "fecha                                 \n",
      "2020-02-14  01001_AM   002-005   9.775\n",
      "2020-02-14  01001_AM   005-010   8.754\n",
      "2020-02-14  01001_AM   002-005   8.431\n",
      "2020-02-14  01001_AM   010-050   9.775\n",
      "2020-02-14  01001_AM   002-005   6.007\n",
      "...              ...       ...     ...\n",
      "2020-02-15   5200108   002-005  10.577\n",
      "2020-02-15   5200108  0005-002  40.256\n",
      "2020-02-15   5200108  0005-002  34.613\n",
      "2020-02-15   5200108  0005-002  12.700\n",
      "2020-02-15   5200108   002-005  10.023\n",
      "\n",
      "[13578411 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "start = \"20200214\"\n",
    "end = \"20200215\"\n",
    "timeseries_o,timeseries_d = concatenar(start,end)\n",
    "\n",
    "#timeseries_o.to_csv(\"2dointento_o.csv\")\n",
    "#timeseries_d.to_csv(\"2dointento_d.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
